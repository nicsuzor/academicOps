---
name: session-insights
description: Extract accomplishments and learnings from Claude Code sessions. Updates daily summary and mines for framework patterns.
allowed-tools: Read,Bash,Task,Edit,Write
version: 3.1.0
permalink: skills-session-insights
---

# Session Insights Skill

Routine command for daily session processing. Runs parallel agents for speed.

## Arguments

- `today` (default) - process today's sessions
- `YYYYMMDD` - process specific date

## Execution (Follow These Steps Exactly)

### Step 1: Find Sessions Needing Transcripts

```bash
cd $AOPS && uv run python skills/session-insights/scripts/find_sessions.py
# Or for a specific date:
cd $AOPS && uv run python skills/session-insights/scripts/find_sessions.py --date YYYYMMDD
```

Output: lines of `session_path|session_id_prefix|shortproject`

### Step 2: Generate Transcripts

For EACH line from Step 1, run Bash directly (no need for Task agents):

```bash
cd $AOPS && uv run python scripts/claude_transcript.py \
  {session_path} \
  -o $ACA_DATA/sessions/claude/YYYYMMDD-{shortproject}-{session_id}
```

Run multiple Bash calls in parallel for speed.

### Step 2b: Verify Transcripts

```bash
ls $ACA_DATA/sessions/claude/YYYYMMDD*-abridged.md | wc -l
```

If count < expected, check output for failures and re-run.

### Step 3: Extract Narrative Signals

Run the narrative extraction script to capture session context and abandoned todos:

```bash
cd $AOPS && uv run python skills/session-insights/scripts/extract_narrative.py --date YYYYMMDD
```

This outputs markdown sections for:
- **Session Context**: Timestamped first prompts showing what work was started
- **Abandoned Todos**: Items left pending/in_progress at session end

Save this output - you'll incorporate it into the daily note in the next step.

### Step 4: Update Daily Summary

Update daily note at `$ACA_DATA/sessions/YYYYMMDD-daily.md`.

If the note exists:
- Read() the ENTIRE note
- incorporate new information into the existing structure
- you may consolidate related information but DO NOT delete unique user observations or tasks from other machines

If the note does NOT exist:
- Create the note from the template in [[templates/daily.md]]

Read the generated abridged transcripts and extract accomplishments:

```bash
ls $ACA_DATA/sessions/claude/YYYYMMDD*-abridged.md
```

For each transcript, identify completed work items and add to daily note under appropriate project headers.

**Daily note format:**
```markdown
# Daily Summary - YYYY-MM-DD

## Focus (Synthesized)
<!-- Auto-generated by synthesize_dashboard.py - do not edit manually -->

## Session Context
- 10:23 AM: Started on prompt hydrator context improvements
- 11:45 AM: Switched to dashboard investigation
- 2:30 PM: SNSF review triple-check

## Today's Priorities
- [ ] Priority task 1
- [ ] Priority task 2

## [[PROJECT]] → [[projects/slug]]
- [x] Accomplishment from sessions
- [ ] Outstanding task

## Abandoned Todos
- [ ] Task left pending (from session abc123)
- [ ] In-progress item not completed (from session def456)

## Session Log
| Session | Project | Summary |
|---------|---------|---------|
| abc123 | writing | Brief description |
```

**Note**: Accomplishments are recorded under their respective project headers with `[x]` markers. Session Context and Abandoned Todos come from the narrative extraction script.

### Step 5: Mine for Learnings (Parallel)

For EACH abridged transcript, spawn a Task agent for Gemini analysis (max 8 concurrent):

```
Task(
  subagent_type="general-purpose",
  model="haiku",
  description="Mine: {shortproject}",
  prompt="
Call mcp__gemini__ask-gemini with this prompt:

@{transcript_path}

Analyze this Claude Code session. Extract:
1. USER CORRECTIONS - where user corrected agent behavior
2. FAILURES - mistakes requiring intervention
3. SUCCESSES - tasks completed well

Return JSON:
{
  \"corrections\": [{\"action\": \"...\", \"feedback\": \"...\", \"lesson\": \"...\"}],
  \"failures\": [{\"description\": \"...\", \"category\": \"...\"}],
  \"successes\": [{\"description\": \"...\"}]
}
"
)
```

### Step 6: Route Findings

Collect Gemini outputs. 
- For each extracted insight, invoke Skill(skill="learning-log", args="...").
- Run up to 8 skills in parallel.

---

## Output Locations

| Artifact | Location | Format |
|----------|----------|--------|
| Transcripts (full) | `$ACA_DATA/sessions/claude/YYYYMMDD-{project}-{sessionid}-*-full.md` | Markdown with YAML frontmatter |
| Transcripts (abridged) | `$ACA_DATA/sessions/claude/YYYYMMDD-{project}-{sessionid}-*-abridged.md` | Markdown with YAML frontmatter |
| Daily summary | `$ACA_DATA/sessions/YYYYMMDD-daily.md` | Markdown with PRIMARY/SECONDARY sections |
| Learning observations | GitHub Issues (nicsuzor/academicOps) | Via `/log` skill → Issues |

## Output Summary

```
## Session Insights - YYYY-MM-DD

### Transcripts
- Generated: N | Skipped: M

### Daily Summary
- Updated: sessions/YYYYMMDD-daily.md

### Learnings
- insight ...
- insight ...

```

## Constraints

- **Parallel execution**: Use multiple Bash calls for transcripts; Task agents only for Gemini mining
- **Idempotent**: Safe to run multiple times; do not delete existing information
- **No judgment**: Follow steps exactly, don't improvise
