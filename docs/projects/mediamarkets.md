<!-- AUTO-GENERATED by bot/scripts/project_sync.py -->
<!-- Last updated: 2025-10-04T00:00:00Z -->
<!-- DO NOT EDIT MANUALLY - Changes will be overwritten -->

# Project: MediaMarkets

## Classification

- **Type**: Research Application
- **Status**: Active
- **Priority**: High
- **Goal**: Academic Profile (PhD student dependency)

## Quick Facts

- **Location**: `projects/mediamarkets/`
- **Strategic Doc**: `data/projects/mediamarkets.md`
- **Tech Stack**: dbt, BigQuery, Python/Buttermilk scrapers, IMDB public data
- **Dependencies**: buttermilk (scraping, data collection)
- **Source of Truth**: `projects/mediamarkets/dbt/` for all transformations

## Purpose

Academic research on film availability across SVOD platforms (Australia/US):

- Track which films available on which platforms over time
- Analyze content library patterns
- Support PhD research (Joel, supervised by Nic)
- High standards: data integrity, reproducibility, documentation

## Architecture

**dbt-Centric Pattern**:

```
Data Sources
  ├── IMDB Public Data (bigquery-public-data.imdb.title_basics)
  └── Platform Scrapers (Buttermilk) → BigQuery raw tables
       ↓
  dbt Project (projects/mediamarkets/dbt/)
       ├── Sources (formal declarations of raw data)
       ├── Staging (clean, standardize, cast)
       └── Marts (fct_availability, dim_titles)
       ↓
  Analysis (on clean, documented models)
```

**Key Principle**: One-way data dependency

- Buttermilk produces raw data
- dbt transforms it
- Analysis consumes dbt models (NEVER raw data)

**Documentation**: `dbt` schema.yml files are definitive guide

## Development

**dbt Setup**:

```bash
cd projects/mediamarkets/dbt
pip install dbt-bigquery
dbt deps  # Install packages
```

**dbt Workflow**:

```bash
dbt run     # Execute models
dbt test    # Run data tests
dbt docs generate  # Generate documentation
dbt docs serve     # View docs locally
```

**Scraper Development**:

```bash
cd projects/mediamarkets
pip install uv
uv install
python -m buttermilk.scripts.validate_scrapers
```

## Data Architecture

**Sources**:

1. **IMDB Public Data**: Film metadata (title, year, genre)
   - Table: `bigquery-public-data.imdb.title_basics`
   - Filter: `title_type = 'movie'`
   - Known issue: `startYear` data quality needs validation

2. **Platform Availability**: Scraping process (Buttermilk)
   - Raw output → BigQuery table
   - Platforms: Netflix, Amazon Prime, Disney+, etc.
   - Frequency: TBD based on research needs

**dbt Models**:

- **Staging**: Clean raw data (e.g., `stg_imdb_titles`, `stg_platform_availability`)
- **Marts**: Business logic (e.g., `fct_availability`, `dim_titles`, `dim_platforms`)
- **Tests**: Data quality validation (not-null, unique, relationships)

## Impact Analysis

### Changes Here Affect

**Stakeholders**:

- Joel (PhD student) - PRIMARY DEPENDENCY
- Academic publications
- Potential industry collaborators

**Risk Level**: HIGH

- PhD timeline dependency
- Data integrity requirements
- Reproducibility standards

### Changes to Dependencies Affect This

**Buttermilk Changes**:

- **Scraping API**: May break data collection
- **Storage Interface**: May affect raw data writes
- **Configuration**: Update scraper configs

**Protocol**:

1. Buttermilk changes → validate scrapers
2. Run test scrape → verify BigQuery writes
3. Run dbt tests → ensure transformations work
4. Any failure → HALT

**dbt Ecosystem Changes**:

- dbt-bigquery version updates → test full pipeline
- New dbt features → evaluate for adoption
- Schema changes → version models, update docs

## Recent Activity

<!-- AUTO-POPULATED by project_sync.py -->

### Week of 2025-09-22

- Scraper development significantly expanded
- Originally planned as 2-day effort, consumed entire week
- Note: Scope creep risk for future scraper work

### Previous

- dbt project structure designed
- Source declarations planned
- IMDB data quality investigation ongoing

## Current State

**dbt Project**: Structure defined, models in development **Scrapers**: In active development (Buttermilk-based) **Data Pipeline**: Raw → Staging in progress **Open Issues**: IMDB startYear data quality **Strategic Context**: Critical for Joel's PhD

## Critical Reminders for Agents

1. **dbt is source of truth** - all transformations documented in schema.yml
2. **One-way dependency** - Buttermilk → dbt → analysis (never reverse)
3. **Test before commit** - `dbt test` must pass
4. **Document everything** - schema.yml for all models and columns
5. **Joel's timeline** - this is blocking PhD work
6. **Scraper scope** - be careful of scope creep (Week of 2025-09-22 lesson)
7. **Update strategic doc** via `project_sync.py` after milestones

## Development Roadmap

**Current Phase**: Data ingestion and staging

1. Set up dbt project structure and sources
2. Develop staging models for IMDB data
3. Design and develop Buttermilk scraper for SVOD platforms
4. Develop dbt models to process scraped data
5. Conduct analysis on final data marts

**Future**: Analysis integration, publication support

## Related Documentation

- Strategic context: `data/projects/mediamarkets.md`
- dbt documentation: `projects/mediamarkets/dbt/` (run `dbt docs serve`)
- Buttermilk scrapers: `projects/buttermilk/docs/` (scraping guides)
- Cross-cutting concerns: `docs/CROSS_CUTTING_CONCERNS.md`
